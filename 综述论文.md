## 词相似度计算（佳音）


## 句相似度计算（可欣）
### 相似度检测方法
用于计算两句子间语义相似度的方法非常广泛，下面是常见的几种方法。

#### 基准方法
  估计两句子间语义相似度最简单的方法就是求句子中所有单词词嵌入的平均值，然后计算两句子词嵌入之间的余弦相似性。很显然，这种简单的基准方法会带来很多变数。我们将研究，如果忽略终止词并用 TF-IDF 计算平均权重会带来怎样的影响。

#### 词移距离
  替代上述基准方法的其中一种有趣方法就是词移距离（Word Mover’s Distance）。词移距离使用两文本间的词嵌入，测量其中一文本中的单词在语义空间中移动到另一文本单词所需要的最短距离。
  
#### Smooth Inverse Frequency
  从语义上来讲，求一句话中词嵌入的平均值似乎给与不相关的单词太多权重了。而 Smooth Inverse Frequency 试着用两种方法解决这一问题：
加权：就像上文用的 TF-IDF，SIF取句中词嵌入的平均权重。每个词嵌入都由 a/(a + p(w)) 进行加权，其中 a 的值经常被设置为0.01，而 p(w) 是词语在语料中预计出现的频率。
  常见元素删除：接下来，SIF 计算了句子的嵌入中最重要的元素。然后它减去这些句子嵌入中的主要成分。这就可以删除与频率和句法有关的变量，他们和语义的联系不大。
  最后，SIF 使一些不重要的词语的权重下降，例如 but、just 等，同时保留对语义贡献较大的信息。

#### 预训练编码器
  预训练编码器的情况比较复杂。但是我们的结果显示编码器还不能完全利用训练的成果。谷歌的句子编码器看起来要比InferSent好一些，但是皮尔森相关系数的结果与SIF的差别不大。


## 编辑距离



## 编辑距离的应用
### BK树
#### 介绍

```c
令d(x,y)表示字符串x到y的Levenshtein距离，那么显然：
d(x,y) = 0 当且仅当 x=y （Levenshtein距离为0 <==> 字符串相等）
d(x,y) = d(y,x) （从x变到y的最少步数就是从y变到x的最少步数）
d(x,y) + d(y,z) >= d(x,z) （从x变到z所需的步数不会超过x先变成y再变成z的步数）
```



#### 建树

#### 查询

#### 实现（可能要加代码）



## 一个例子讲解

（要不代码加到这里）

## 树结构和翻译记忆的关系
